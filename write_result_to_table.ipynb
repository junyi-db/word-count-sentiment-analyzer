{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69c069b7-f634-423d-a00f-79f6ddb20793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "dest_path = dbutils.widgets.get(\"dest_path\")\n",
    "\n",
    "# List all result files\n",
    "result_files = dbutils.fs.ls(\"tmp/\")\n",
    "text_analysis_files = [f.path for f in result_files if f.name.endswith(\"_text_analysis.csv\")]\n",
    "\n",
    "# Define schema explicitly to ensure correct data types\n",
    "schema = StructType([\n",
    "    StructField(\"file_name\", StringType(), True),\n",
    "    StructField(\"raw_text\", StringType(), True),\n",
    "    StructField(\"total_word_count\", IntegerType(), True),\n",
    "    StructField(\"sentiment\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Read each CSV with proper options to handle quoted fields and multiline text\n",
    "df_list = []\n",
    "for path in text_analysis_files:\n",
    "    try:\n",
    "        df = spark.read.format(\"csv\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"multiline\", \"true\") \\\n",
    "            .option(\"quote\", \"\\\"\") \\\n",
    "            .option(\"escape\", \"\\\"\") \\\n",
    "            .schema(schema) \\\n",
    "            .load(path)\n",
    "        \n",
    "        # Show a sample to verify data is loaded correctly\n",
    "        df.select(\"file_name\", \"total_word_count\", \"sentiment\").show(1, truncate=False)\n",
    "        \n",
    "        df_list.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {path}: {str(e)}\")\n",
    "\n",
    "# If there are no files, create an empty dataframe with the right schema\n",
    "if not df_list:\n",
    "    print(\"No valid files found, creating empty dataframe\")\n",
    "    all_results = spark.createDataFrame([], schema)\n",
    "else:\n",
    "    # Union all the outputs\n",
    "    all_results = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        all_results = all_results.union(df)\n",
    "\n",
    "# No need to cast columns as we defined the schema explicitly\n",
    "final_df = all_results\n",
    "\n",
    "# Print the schema and a sample of data for debugging\n",
    "final_df.printSchema()\n",
    "\n",
    "final_df.select(\"file_name\", \"total_word_count\", \"sentiment\").show(5, truncate=False)\n",
    "\n",
    "final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(dest_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_41a50460-c90b-4840-9288-afcb847395d5",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "write_result_to_table",
   "widgets": {
    "dest_path": {
     "currentValue": "jy_demo_catalog.text_analysis_schema.text_analysis",
     "nuid": "cd92fc7a-4da8-4f39-8eba-8ddfcc2c41fa",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "dest_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "dest_path",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
